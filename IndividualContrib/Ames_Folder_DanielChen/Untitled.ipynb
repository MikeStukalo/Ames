{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "https://www.kaggle.com/tadepalli/xgboost-with-n-trees-autostop-0-12638\n",
    "Srini, XGBoost with n_trees autostop: 0.12638\n",
    "\n",
    "https://www.kaggle.com/zoupet/xgboost-ridge-lasso#\n",
    "Julien Heiduk, XGboost + Ridge + Lasso\n",
    "    \n",
    "https://www.kaggle.com/comartel/house-price-xgboost-starter\n",
    "CoMartel, House Price XgBoost starter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://www.kaggle.com/tadepalli/xgboost-with-n-trees-autostop-0-12638\n",
    "# Srini, XGBoost with n_trees autostop: 0.12638\n",
    "  \n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.cross_validation import StratifiedKFold, KFold\n",
    "import xgboost\n",
    "from sklearn.grid_search import ParameterGrid\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "CLASS = False  # Whether classification or regression\n",
    "SCORE_MIN = True  # Optimizing score through minimum\n",
    "k = 5  # Number of folds\n",
    "best_score = 10\n",
    "best_params = None\n",
    "best_iter = None\n",
    "\n",
    "train_name = '../input/train.csv'\n",
    "test_name = '../input/test.csv'\n",
    "submission_name = '../input/sample_submission.csv'\n",
    "submission_col = 'SalePrice'\n",
    "submission_target = 'test_sub1.csv'\n",
    "\n",
    "# Read files\n",
    "train = pd.DataFrame.from_csv(train_name)\n",
    "train = train.fillna(-1)\n",
    "test = pd.DataFrame.from_csv(test_name)\n",
    "test = test.fillna(-1)\n",
    "submission = pd.DataFrame.from_csv(submission_name)\n",
    "# Extract target\n",
    "target = train['SalePrice']\n",
    "del train['SalePrice']\n",
    "\n",
    "# Label nominal variables to numbers\n",
    "columns = train.columns.values\n",
    "nom_numeric_cols = ['MSSubClass']\n",
    "dummy_train = []\n",
    "dummy_test = []\n",
    "for col in columns:\n",
    "    # Only works for nominal data without a lot of factors\n",
    "    if train[col].dtype.name == 'object' or col in nom_numeric_cols:\n",
    "        dummy_train.append(pd.get_dummies(train[col].values.astype(str), col))\n",
    "        dummy_train[-1].index = train.index\n",
    "        dummy_test.append(pd.get_dummies(test[col].values.astype(str), col))\n",
    "        dummy_test[-1].index = test.index\n",
    "        del train[col]\n",
    "        del test[col]\n",
    "train = pd.concat([train] + dummy_train, axis=1)\n",
    "test = pd.concat([test] + dummy_test, axis=1)\n",
    "\n",
    "# Use only common columns\n",
    "columns = []\n",
    "for col_a in train.columns.values:\n",
    "    if col_a in test.columns.values:\n",
    "        columns.append(col_a)\n",
    "train = train[columns]\n",
    "test = test[columns]\n",
    "\n",
    "# CV\n",
    "train = np.array(train)\n",
    "target = np.log(np.array(target))  # Changes to Log\n",
    "test = np.array(test)\n",
    "print(train.shape, test.shape)\n",
    "\n",
    "if CLASS:\n",
    "    kfold = StratifiedKFold(target, k)\n",
    "else:\n",
    "    kfold = KFold(train.shape[0], k)\n",
    "\n",
    "early_stopping = 50\n",
    "\n",
    "param_grid = [\n",
    "              {'silent': [1],\n",
    "               'nthread': [2],\n",
    "               'eval_metric': ['rmse'],\n",
    "               'eta': [0.03],\n",
    "               'objective': ['reg:linear'],\n",
    "               'max_depth': [5, 7],\n",
    "               'num_round': [1000],\n",
    "               'subsample': [0.2, 0.4, 0.6],\n",
    "               'colsample_bytree': [0.3, 0.5, 0.7],\n",
    "               }\n",
    "              ]\n",
    "\n",
    "# Hyperparmeter grid optimization\n",
    "for params in ParameterGrid(param_grid):\n",
    "    print(params)\n",
    "    # Determine best n_rounds\n",
    "    xgboost_rounds = []\n",
    "    for train_index, test_index in kfold:\n",
    "        X_train, X_test = train[train_index], train[test_index]\n",
    "        y_train, y_test = target[train_index], target[test_index]\n",
    "\n",
    "        xg_train = xgboost.DMatrix(X_train, label=y_train)\n",
    "        xg_test = xgboost.DMatrix(X_test, label=y_test)\n",
    "\n",
    "        watchlist = [(xg_train, 'train'), (xg_test, 'test')]\n",
    "\n",
    "        num_round = params['num_round']\n",
    "        xgclassifier = xgboost.train(params, xg_train, num_round,\n",
    "                                     watchlist,\n",
    "                                     early_stopping_rounds=early_stopping);\n",
    "        xgboost_rounds.append(xgclassifier.best_iteration)\n",
    "\n",
    "    num_round = int(np.mean(xgboost_rounds))\n",
    "    print('The best n_rounds is %d' % num_round)\n",
    "    # Solve CV\n",
    "    rmsle_score = []\n",
    "    for cv_train_index, cv_test_index in kfold:\n",
    "        X_train, X_test = train[cv_train_index, :], train[cv_test_index, :]\n",
    "        y_train, y_test = target[cv_train_index], target[cv_test_index]\n",
    "\n",
    "        # train machine learning\n",
    "        xg_train = xgboost.DMatrix(X_train, label=y_train)\n",
    "        xg_test = xgboost.DMatrix(X_test, label=y_test)\n",
    "\n",
    "        watchlist = [(xg_train, 'train'), (xg_test, 'test')]\n",
    "\n",
    "        xgclassifier = xgboost.train(params, xg_train, num_round);\n",
    "\n",
    "        # predict\n",
    "        predicted_results = xgclassifier.predict(xg_test)\n",
    "        rmsle_score.append(np.sqrt(mean_squared_error(y_test, predicted_results)))\n",
    "\n",
    "    if SCORE_MIN:\n",
    "        if best_score > np.mean(rmsle_score):\n",
    "            print(np.mean(rmsle_score))\n",
    "            print('new best')\n",
    "            best_score = np.mean(rmsle_score)\n",
    "            best_params = params\n",
    "            best_iter = num_round\n",
    "    else:\n",
    "        if best_score < np.mean(rmsle_score):\n",
    "            print(np.mean(rmsle_score))\n",
    "            print('new best')\n",
    "            best_score = np.mean(rmsle_score)\n",
    "            best_params = params\n",
    "            best_iter = num_round\n",
    "\n",
    "# Solution using best parameters\n",
    "print('best params: %s' % best_params)\n",
    "print('best score: %f' % best_score)\n",
    "xg_train = xgboost.DMatrix(train, label=target)\n",
    "xg_test = xgboost.DMatrix(test)\n",
    "watchlist = [(xg_train, 'train')]\n",
    "num_round = best_iter  # already int\n",
    "xgclassifier = xgboost.train(best_params, xg_train, num_round, watchlist);\n",
    "submission[submission_col] = np.exp(xgclassifier.predict(xg_test))\n",
    "submission.to_csv(submission_target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
